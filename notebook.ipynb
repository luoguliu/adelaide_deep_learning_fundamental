{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7a0156c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56a8ca02",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "with open('./diabetes_scale.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        tmp = line.strip().split(' ')\n",
    "\n",
    "        assert( len(tmp) <= 9 )\n",
    "        \n",
    "        tmp[0] = int( tmp[0] )\n",
    "        y += [tmp[0]]\n",
    "        \n",
    "        x = [0] * 8\n",
    "        for i in range(1, len(tmp)):\n",
    "            val = tmp[i].split(':')\n",
    "            x[ int(val[0]) - 1 ] = float(val[1])\n",
    "        X += [x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba718522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.294118    0.487437    0.180328   ...  0.00149028 -0.53117\n",
      "  -0.0333333 ]\n",
      " [-0.882353   -0.145729    0.0819672  ... -0.207153   -0.766866\n",
      "  -0.666667  ]\n",
      " [-0.0588235   0.839196    0.0491803  ... -0.305514   -0.492741\n",
      "  -0.633333  ]\n",
      " ...\n",
      " [-0.411765    0.21608     0.180328   ... -0.219076   -0.857387\n",
      "  -0.7       ]\n",
      " [-0.882353    0.266332   -0.0163934  ... -0.102832   -0.768574\n",
      "  -0.133333  ]\n",
      " [-0.882353   -0.0653266   0.147541   ... -0.0938897  -0.797609\n",
      "  -0.933333  ]]\n"
     ]
    }
   ],
   "source": [
    "X = np.array(X)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a963878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1  1 -1  1 -1  1 -1  1 -1 -1  1 -1  1 -1 -1 -1 -1 -1  1 -1  1  1 -1 -1\n",
      " -1 -1 -1  1  1  1  1 -1  1  1  1  1  1 -1 -1 -1  1  1  1 -1  1 -1  1  1\n",
      " -1  1  1  1  1 -1  1  1 -1  1  1  1  1 -1  1  1 -1  1 -1  1  1  1 -1  1\n",
      " -1  1  1  1  1  1 -1  1  1  1  1  1 -1  1  1  1 -1  1  1  1  1 -1  1  1\n",
      "  1  1  1 -1 -1  1  1  1  1  1  1  1  1 -1 -1 -1  1  1 -1 -1 -1  1  1  1\n",
      " -1  1  1  1 -1 -1  1  1 -1 -1 -1 -1 -1  1  1  1  1  1  1  1  1  1  1 -1\n",
      "  1  1  1  1  1  1  1  1 -1  1 -1 -1  1  1  1 -1  1  1  1  1 -1 -1  1  1\n",
      "  1  1 -1 -1  1  1  1 -1  1 -1  1 -1  1  1  1  1  1 -1 -1 -1 -1 -1  1  1\n",
      " -1 -1  1 -1  1 -1 -1 -1  1  1  1  1  1  1 -1 -1  1 -1  1  1  1 -1 -1 -1\n",
      " -1  1 -1 -1 -1 -1  1  1  1  1  1 -1  1  1 -1 -1  1  1  1 -1 -1 -1 -1  1\n",
      "  1  1 -1 -1  1 -1  1  1  1  1  1  1  1  1 -1 -1  1  1  1 -1  1 -1  1  1\n",
      " -1  1 -1  1  1 -1 -1  1  1  1  1  1 -1  1  1  1 -1  1  1 -1 -1  1  1 -1\n",
      "  1  1  1 -1 -1 -1  1  1 -1  1 -1  1 -1 -1  1 -1  1  1 -1  1 -1 -1  1  1\n",
      " -1  1 -1  1  1 -1  1 -1  1 -1 -1 -1  1  1 -1  1 -1  1  1  1 -1  1  1  1\n",
      "  1 -1 -1 -1  1  1  1  1  1  1  1  1  1 -1  1  1  1  1  1 -1 -1 -1  1 -1\n",
      " -1  1  1 -1  1  1 -1  1  1 -1 -1  1  1  1  1 -1  1  1 -1  1  1  1  1  1\n",
      "  1  1 -1 -1 -1  1  1 -1  1  1 -1  1  1 -1  1 -1 -1  1 -1  1 -1  1 -1  1\n",
      " -1 -1  1  1  1  1 -1 -1  1 -1  1 -1  1  1  1  1 -1 -1  1 -1  1 -1  1  1\n",
      "  1  1  1 -1  1  1  1  1 -1  1  1 -1 -1 -1  1  1 -1  1  1 -1  1  1  1 -1\n",
      "  1  1 -1  1  1  1  1  1  1  1  1  1 -1  1  1  1  1  1  1  1 -1  1  1  1\n",
      " -1  1  1  1 -1 -1  1  1  1  1  1  1  1 -1  1  1  1  1 -1  1  1  1 -1  1\n",
      "  1  1 -1  1  1  1 -1  1  1  1  1 -1 -1  1  1  1  1  1  1 -1  1  1  1  1\n",
      "  1  1  1  1  1  1  1 -1  1  1  1 -1 -1 -1 -1  1  1 -1 -1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1 -1 -1  1  1  1  1  1  1  1 -1  1  1  1  1  1  1\n",
      "  1 -1  1 -1 -1  1  1  1 -1  1 -1  1 -1  1 -1  1 -1  1  1 -1  1  1 -1  1\n",
      "  1  1  1 -1 -1  1 -1  1  1  1  1 -1 -1  1 -1  1  1  1 -1 -1  1  1  1  1\n",
      "  1  1  1  1  1  1 -1  1  1  1  1 -1  1  1 -1  1  1  1 -1  1  1  1 -1 -1\n",
      " -1  1  1  1  1  1  1 -1  1  1  1 -1  1 -1 -1 -1 -1  1 -1 -1  1  1  1  1\n",
      "  1  1  1 -1 -1  1 -1  1  1 -1  1 -1  1  1  1  1  1 -1  1 -1  1 -1  1 -1\n",
      " -1  1  1  1  1 -1 -1  1  1  1 -1  1 -1 -1  1  1 -1  1  1 -1 -1  1  1 -1\n",
      "  1  1 -1  1  1  1  1  1  1  1 -1 -1 -1  1  1  1  1  1  1 -1 -1  1  1 -1\n",
      "  1  1 -1  1 -1 -1 -1  1  1 -1 -1 -1  1 -1  1 -1  1 -1  1  1  1  1 -1  1]\n"
     ]
    }
   ],
   "source": [
    "y = np.array(y)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93d5e391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 8) (768,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4dd09d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700, 8) (68, 8)\n",
      "(700,) (68,)\n"
     ]
    }
   ],
   "source": [
    "# train/test split\n",
    "X_train = X[:700]\n",
    "X_test = X[700:]\n",
    "print(X_train.shape, X_test.shape)\n",
    "\n",
    "y_train = y[:700]\n",
    "y_test = y[700:]\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5088eefb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "459\n",
      "241\n",
      "41\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "# check test data\n",
    "print(np.sum(y_train == 1))\n",
    "print(np.sum(y_train == -1))\n",
    "\n",
    "print(np.sum(y_test == 1))\n",
    "print(np.sum(y_test == -1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "50674a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(68,)\n",
      "[ 1  1 -1 -1  1  1  1  1 -1  1  1  1  1  1  1 -1 -1  1  1  1  1  1 -1  1\n",
      " -1  1  1  1  1  1  1  1 -1  1 -1  1  1  1  1  1 -1  1  1  1 -1 -1  1  1\n",
      " -1 -1 -1  1  1  1  1 -1  1 -1  1  1  1 -1  1  1  1  1 -1  1]\n",
      "0.7352941176470589\n"
     ]
    }
   ],
   "source": [
    "# try some sklearn models\n",
    "\n",
    "# KNN\n",
    "import sklearn.neighbors\n",
    "knn = sklearn.neighbors.KNeighborsClassifier(n_neighbors = 5)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "print(y_pred.shape)\n",
    "print(y_pred)\n",
    "\n",
    "import sklearn.metrics\n",
    "print( sklearn.metrics.accuracy_score(y_test, y_pred) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d84cadf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6617647058823529\n"
     ]
    }
   ],
   "source": [
    "# Tree\n",
    "import sklearn.tree\n",
    "dt = sklearn.tree.DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred = dt.predict(X_test)\n",
    "\n",
    "print( sklearn.metrics.accuracy_score(y_test, y_pred) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e63844cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7794117647058824\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "import sklearn.ensemble\n",
    "rf = sklearn.ensemble.RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "print( sklearn.metrics.accuracy_score(y_test, y_pred) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c4d6793a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7941176470588235\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "import sklearn.linear_model\n",
    "lr = sklearn.linear_model.LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "print( sklearn.metrics.accuracy_score(y_test, y_pred) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3cf5d5fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8088235294117647\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "import sklearn.svm\n",
    "svc = sklearn.svm.LinearSVC(dual = True)\n",
    "svc.fit(X_train, y_train)\n",
    "y_pred = svc.predict(X_test)\n",
    "\n",
    "print( sklearn.metrics.accuracy_score(y_test, y_pred) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0232278f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7941176470588235\n"
     ]
    }
   ],
   "source": [
    "# MLP\n",
    "\n",
    "# adjust parameter\n",
    "import sklearn.neural_network\n",
    "\n",
    "mlp_1 = sklearn.neural_network.MLPClassifier(\n",
    "    hidden_layer_sizes=(100,), activation='relu', solver='sgd', alpha=0.0001, \n",
    "    batch_size='auto', learning_rate='constant', learning_rate_init=0.001, max_iter=1000)\n",
    "mlp_1.fit(X_train, y_train)\n",
    "y_pred = mlp_1.predict(X_test)\n",
    "\n",
    "print( sklearn.metrics.accuracy_score(y_test, y_pred) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c9118d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6029411764705882\n"
     ]
    }
   ],
   "source": [
    "mlp_2 = sklearn.neural_network.MLPClassifier(\n",
    "    hidden_layer_sizes=(100,), activation='logistic', solver='sgd', alpha=0.0001, \n",
    "    batch_size='auto', learning_rate='constant', learning_rate_init=0.001, max_iter=1000)\n",
    "mlp_2.fit(X_train, y_train)\n",
    "y_pred = mlp_2.predict(X_test)\n",
    "\n",
    "print( sklearn.metrics.accuracy_score(y_test, y_pred) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7e4d74c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8088235294117647\n"
     ]
    }
   ],
   "source": [
    "mlp_2 = sklearn.neural_network.MLPClassifier(\n",
    "    hidden_layer_sizes=(100,), activation='tanh', solver='sgd', alpha=0.0001, \n",
    "    batch_size='auto', learning_rate='constant', learning_rate_init=0.001, max_iter=1000)\n",
    "mlp_2.fit(X_train, y_train)\n",
    "y_pred = mlp_2.predict(X_test)\n",
    "\n",
    "print( sklearn.metrics.accuracy_score(y_test, y_pred) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0883fdbc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6029411764705882\n"
     ]
    }
   ],
   "source": [
    "mlp_3 = sklearn.neural_network.MLPClassifier(\n",
    "    hidden_layer_sizes=(100,), activation='tanh', solver='sgd', alpha=0.0001, \n",
    "    batch_size='auto', learning_rate='constant', learning_rate_init=0.0001, max_iter=10000)\n",
    "mlp_3.fit(X_train, y_train)\n",
    "y_pred = mlp_3.predict(X_test)\n",
    "\n",
    "print( sklearn.metrics.accuracy_score(y_test, y_pred) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4c165198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8088235294117647\n"
     ]
    }
   ],
   "source": [
    "mlp_4 = sklearn.neural_network.MLPClassifier(\n",
    "    hidden_layer_sizes=(250,), activation='tanh', solver='sgd', alpha=0.0001, \n",
    "    batch_size='auto', learning_rate='constant', learning_rate_init=0.001, max_iter=1000)\n",
    "mlp_4.fit(X_train, y_train)\n",
    "y_pred = mlp_4.predict(X_test)\n",
    "\n",
    "print( sklearn.metrics.accuracy_score(y_test, y_pred) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e9c3aeaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8088235294117647\n"
     ]
    }
   ],
   "source": [
    "mlp_5 = sklearn.neural_network.MLPClassifier(\n",
    "    hidden_layer_sizes=(100, 64, 32, 16, ), activation='tanh', solver='sgd', alpha=0.0001, \n",
    "    batch_size='auto', learning_rate='constant', learning_rate_init=0.001, max_iter=1000)\n",
    "mlp_5.fit(X_train, y_train)\n",
    "y_pred = mlp_5.predict(X_test)\n",
    "\n",
    "print( sklearn.metrics.accuracy_score(y_test, y_pred) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0eb8d375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7647058823529411\n"
     ]
    }
   ],
   "source": [
    "# Simple Perceptron\n",
    "\n",
    "pct = sklearn.linear_model.Perceptron()\n",
    "pct.fit(X_train, y_train)\n",
    "y_pred = pct.predict(X_test)\n",
    "\n",
    "print( sklearn.metrics.accuracy_score(y_test, y_pred) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604d19f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03a5bf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4248ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "355956cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6176470588235294"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# My implementation\n",
    "\n",
    "\n",
    "import torch\n",
    "\n",
    "class Perceptron(torch.nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.linear = torch.nn.Linear(input_dim, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return torch.sigmoid(self.linear(x))\n",
    "    \n",
    "def train(model, train_inputs, train_labels, epochs=1000, learning_rate=0.001):\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "    criterion = torch.nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(train_inputs)\n",
    "        loss = criterion(output, train_labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "def test(model, test_inputs, test_labels):\n",
    "    output = model(test_inputs)\n",
    "    correct = 0\n",
    "    for i in range(len(test_labels)):\n",
    "        if output[i] > 0.5:\n",
    "            pred = 1\n",
    "        else:\n",
    "            pred = 0\n",
    "        if pred == test_labels[i]:\n",
    "            correct += 1\n",
    "    return correct / len(test_labels)\n",
    "\n",
    "\n",
    "model = Perceptron(8)\n",
    "\n",
    "N = X_train.shape[0]\n",
    "yy_train = np.array(y_train)\n",
    "yy_train[yy_train == -1] = 0\n",
    "train(model, \n",
    "      torch.tensor(X_train, dtype=torch.float), \n",
    "      torch.tensor(yy_train.reshape((N,1)), dtype=torch.float))\n",
    "\n",
    "N = X_test.shape[0]\n",
    "yy_test = np.array(y_test)\n",
    "yy_test[yy_test == -1] = 0\n",
    "test(model, \n",
    "     torch.tensor(X_test, dtype=torch.float), \n",
    "     torch.tensor(yy_test.reshape((N,1)), dtype=torch.float))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3724107",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
